[api_keys]
# OpenAI
openai = 

# Anthropic
anthropic = 

# Mistral
mistral = 

# AI21
ai21 = 

# Amazon Bedrock
aws_access_key_id = 
aws_secret_access_key = 
aws_region = 

# Cohere
cohere = 

[model_settings]
default_model = claude-3-haiku-20240307
temperature = 0.7
max_tokens = 1000

[available_models]
# OpenAI Models
openai_models = gpt-4-1106-preview,gpt-4-32k-0314,gpt-4-0125-preview,gpt-4-turbo-preview,gpt-4,gpt-4-0314,gpt-4-0613,gpt-4-turbo,gpt-4-turbo-2024-04-09,gpt-3.5-turbo,gpt-3.5-turbo-0301,gpt-3.5-turbo-0613,gpt-3.5-turbo-16k,gpt-3.5-turbo-16k-0613,gpt-3.5-turbo-0125,gpt-3.5-turbo-1106,gpt-3.5-turbo-instruct,gpt-3.5-turbo-instruct-0914

# Anthropic Models
anthropic_models = claude-3-opus-20240229,claude-3-sonnet-20240229,claude-3-haiku-20240307,claude-3-5-sonnet-20240620,claude-3-5-sonnet-20241022,claude-3-5-sonnet-latest

# Mistral Models
mistral_models = mistral.mistral-7b-instruct-v0:2,mistral.mixtral-8x7b-instruct-v0:1,mistral.mistral-large-2402-v1:0,mistral.mistral-small-2402-v1:0

# AI21 Models
ai21_models = ai21.jamba-instruct-v1:0,ai21.j2-ultra-v1,ai21.j2-mid-v1

# Amazon Titan Models
amazon_models = amazon.titan-text-lite-v1,amazon.titan-text-express-v1,amazon.titan-embed-text-v1,amazon.titan-image-generator-v1,amazon.titan-image-generator-v2:0

# Cohere Models
cohere_models = cohere.command-r-plus-v1:0,cohere.command-r-v1:0,cohere.command-text-v14,cohere.embed-english-v3,cohere.embed-multilingual-v3

# Meta Llama Models
meta_models = meta.llama3-8b-instruct-v1:0,meta.llama3-70b-instruct-v1:0,meta.llama2-13b-chat-v1,meta.llama2-70b-chat-v1,meta.llama2-13b-v1

[model_parameters]
# Common parameters
temperature = 0.7
max_tokens = 1000
top_p = 1.0
frequency_penalty = 0.0
presence_penalty = 0.0

[model_parameters.gpt-4]
temperature = 0.7
max_tokens = 8192

[model_parameters.claude-3-opus]
temperature = 0.7
max_tokens = 4096

[model_parameters.mistral-large]
temperature = 0.7
max_tokens = 4096

[rate_limits]
max_retries = 3
retry_delay = 1
requests_per_minute = 60

[rate_limits.openai]
requests_per_minute = 60
tokens_per_minute = 90000

[rate_limits.anthropic]
requests_per_minute = 50
tokens_per_minute = 100000

[rate_limits.mistral]
requests_per_minute = 40
tokens_per_minute = 80000

[logging]
level = INFO
format = %(asctime)s - %(name)s - %(levelname)s - %(message)s
file_path = logs/agentflow.log
max_bytes = 10485760
backup_count = 5

[model_fallbacks]
openai = gpt-4,gpt-3.5-turbo
anthropic = claude-3-opus-20240229,claude-3-sonnet-20240229,claude-3-haiku-20240307
mistral = mistral.mistral-large-2402-v1:0,mistral.mistral-small-2402-v1:0

[provider_priorities]
order = anthropic,openai,mistral,ai21,amazon,cohere,meta